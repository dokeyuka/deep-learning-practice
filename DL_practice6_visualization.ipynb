{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_practice6_visualization.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNnoHc8vWlKX2mXNp7MD9P/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dokeyuka/deep-learning-practice/blob/main/DL_practice6_visualization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lJvDs5Lu5q1X",
        "outputId": "75b3bc22-1de7-400f-95e1-c75bdb208320"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:1, loss: 2.283, a㏄:0.160, val_loss:2.251, val_acc:0.322\n",
            "epoch:2, loss: 2.098, a㏄:0.498, val_loss:1.701, val_acc:0.596\n",
            "epoch:3, loss: 1.098, a㏄:0.709, val_loss:0.720, val_acc:0.789\n",
            "epoch:4, loss: 0.613, a㏄:0.820, val_loss:0.501, val_acc:0.852\n",
            "epoch:5, loss: 0.472, a㏄:0.864, val_loss:0.417, val_acc:0.879\n",
            "epoch:6, loss: 0.407, a㏄:0.884, val_loss:0.375, val_acc:0.890\n",
            "epoch:7, loss: 0.370, a㏄:0.894, val_loss:0.344, val_acc:0.900\n",
            "epoch:8, loss: 0.344, a㏄:0.902, val_loss:0.324, val_acc:0.903\n",
            "epoch:9, loss: 0.324, a㏄:0.908, val_loss:0.306, val_acc:0.912\n",
            "epoch:10, loss: 0.306, a㏄:0.912, val_loss:0.292, val_acc:0.915\n",
            "epoch:11, loss: 0.290, a㏄:0.918, val_loss:0.278, val_acc:0.919\n",
            "epoch:12, loss: 0.275, a㏄:0.922, val_loss:0.264, val_acc:0.923\n",
            "epoch:13, loss: 0.261, a㏄:0.926, val_loss:0.253, val_acc:0.927\n",
            "epoch:14, loss: 0.249, a㏄:0.929, val_loss:0.241, val_acc:0.930\n",
            "epoch:15, loss: 0.236, a㏄:0.933, val_loss:0.232, val_acc:0.933\n",
            "epoch:16, loss: 0.224, a㏄:0.936, val_loss:0.218, val_acc:0.935\n",
            "epoch:17, loss: 0.213, a㏄:0.940, val_loss:0.207, val_acc:0.939\n",
            "epoch:18, loss: 0.202, a㏄:0.943, val_loss:0.200, val_acc:0.941\n",
            "epoch:19, loss: 0.192, a㏄:0.946, val_loss:0.192, val_acc:0.944\n",
            "epoch:20, loss: 0.183, a㏄:0.948, val_loss:0.185, val_acc:0.946\n",
            "epoch:21, loss: 0.175, a㏄:0.951, val_loss:0.178, val_acc:0.948\n",
            "epoch:22, loss: 0.167, a㏄:0.953, val_loss:0.169, val_acc:0.949\n",
            "epoch:23, loss: 0.160, a㏄:0.955, val_loss:0.167, val_acc:0.950\n",
            "epoch:24, loss: 0.153, a㏄:0.957, val_loss:0.158, val_acc:0.954\n",
            "epoch:25, loss: 0.147, a㏄:0.959, val_loss:0.152, val_acc:0.955\n",
            "epoch:26, loss: 0.140, a㏄:0.961, val_loss:0.147, val_acc:0.955\n",
            "epoch:27, loss: 0.135, a㏄:0.962, val_loss:0.149, val_acc:0.955\n",
            "epoch:28, loss: 0.130, a㏄:0.963, val_loss:0.140, val_acc:0.959\n",
            "epoch:29, loss: 0.125, a㏄:0.965, val_loss:0.138, val_acc:0.960\n",
            "epoch:30, loss: 0.120, a㏄:0.966, val_loss:0.134, val_acc:0.961\n",
            "epoch:31, loss: 0.116, a㏄:0.968, val_loss:0.130, val_acc:0.960\n",
            "epoch:32, loss: 0.112, a㏄:0.969, val_loss:0.128, val_acc:0.963\n",
            "epoch:33, loss: 0.108, a㏄:0.970, val_loss:0.126, val_acc:0.962\n",
            "epoch:34, loss: 0.104, a㏄:0.971, val_loss:0.123, val_acc:0.963\n",
            "epoch:35, loss: 0.100, a㏄:0.972, val_loss:0.122, val_acc:0.962\n",
            "epoch:36, loss: 0.097, a㏄:0.973, val_loss:0.118, val_acc:0.965\n",
            "epoch:37, loss: 0.094, a㏄:0.974, val_loss:0.119, val_acc:0.964\n",
            "epoch:38, loss: 0.091, a㏄:0.975, val_loss:0.114, val_acc:0.966\n",
            "epoch:39, loss: 0.088, a㏄:0.975, val_loss:0.116, val_acc:0.964\n",
            "epoch:40, loss: 0.085, a㏄:0.976, val_loss:0.114, val_acc:0.966\n",
            "epoch:41, loss: 0.082, a㏄:0.977, val_loss:0.110, val_acc:0.967\n",
            "epoch:42, loss: 0.080, a㏄:0.978, val_loss:0.106, val_acc:0.968\n",
            "epoch:43, loss: 0.078, a㏄:0.978, val_loss:0.106, val_acc:0.968\n",
            "epoch:44, loss: 0.075, a㏄:0.979, val_loss:0.105, val_acc:0.970\n",
            "epoch:45, loss: 0.073, a㏄:0.980, val_loss:0.106, val_acc:0.969\n",
            "epoch:46, loss: 0.070, a㏄:0.981, val_loss:0.103, val_acc:0.968\n",
            "epoch:47, loss: 0.068, a㏄:0.982, val_loss:0.103, val_acc:0.969\n",
            "epoch:48, loss: 0.066, a㏄:0.982, val_loss:0.104, val_acc:0.968\n",
            "epoch:49, loss: 0.064, a㏄:0.982, val_loss:0.101, val_acc:0.969\n",
            "epoch:50, loss: 0.062, a㏄:0.983, val_loss:0.099, val_acc:0.970\n",
            "epoch:51, loss: 0.061, a㏄:0.984, val_loss:0.097, val_acc:0.971\n",
            "epoch:52, loss: 0.059, a㏄:0.984, val_loss:0.097, val_acc:0.971\n",
            "epoch:53, loss: 0.057, a㏄:0.985, val_loss:0.100, val_acc:0.971\n",
            "epoch:54, loss: 0.055, a㏄:0.985, val_loss:0.097, val_acc:0.971\n",
            "epoch:55, loss: 0.054, a㏄:0.986, val_loss:0.096, val_acc:0.972\n",
            "epoch:56, loss: 0.052, a㏄:0.986, val_loss:0.096, val_acc:0.972\n",
            "epoch:57, loss: 0.050, a㏄:0.987, val_loss:0.092, val_acc:0.972\n",
            "epoch:58, loss: 0.049, a㏄:0.987, val_loss:0.093, val_acc:0.972\n",
            "epoch:59, loss: 0.047, a㏄:0.988, val_loss:0.095, val_acc:0.971\n",
            "epoch:60, loss: 0.046, a㏄:0.988, val_loss:0.091, val_acc:0.973\n",
            "epoch:61, loss: 0.045, a㏄:0.989, val_loss:0.092, val_acc:0.974\n",
            "epoch:62, loss: 0.044, a㏄:0.989, val_loss:0.092, val_acc:0.973\n",
            "epoch:63, loss: 0.042, a㏄:0.989, val_loss:0.092, val_acc:0.972\n",
            "epoch:64, loss: 0.041, a㏄:0.990, val_loss:0.091, val_acc:0.974\n",
            "epoch:65, loss: 0.040, a㏄:0.990, val_loss:0.090, val_acc:0.973\n",
            "epoch:66, loss: 0.039, a㏄:0.991, val_loss:0.091, val_acc:0.973\n",
            "epoch:67, loss: 0.038, a㏄:0.991, val_loss:0.090, val_acc:0.974\n",
            "epoch:68, loss: 0.036, a㏄:0.991, val_loss:0.090, val_acc:0.974\n",
            "epoch:69, loss: 0.035, a㏄:0.992, val_loss:0.089, val_acc:0.974\n",
            "epoch:70, loss: 0.034, a㏄:0.992, val_loss:0.088, val_acc:0.974\n",
            "epoch:71, loss: 0.033, a㏄:0.992, val_loss:0.088, val_acc:0.974\n",
            "epoch:72, loss: 0.032, a㏄:0.993, val_loss:0.089, val_acc:0.973\n",
            "epoch:73, loss: 0.031, a㏄:0.993, val_loss:0.094, val_acc:0.973\n",
            "epoch:74, loss: 0.030, a㏄:0.993, val_loss:0.088, val_acc:0.974\n",
            "epoch:75, loss: 0.030, a㏄:0.993, val_loss:0.088, val_acc:0.974\n",
            "epoch:76, loss: 0.029, a㏄:0.994, val_loss:0.089, val_acc:0.974\n",
            "epoch:77, loss: 0.028, a㏄:0.994, val_loss:0.091, val_acc:0.974\n",
            "epoch:78, loss: 0.027, a㏄:0.994, val_loss:0.088, val_acc:0.974\n",
            "epoch:79, loss: 0.026, a㏄:0.995, val_loss:0.088, val_acc:0.974\n",
            "epoch:80, loss: 0.025, a㏄:0.995, val_loss:0.088, val_acc:0.975\n",
            "epoch:81, loss: 0.024, a㏄:0.995, val_loss:0.089, val_acc:0.975\n",
            "epoch:82, loss: 0.024, a㏄:0.995, val_loss:0.089, val_acc:0.974\n",
            "epoch:83, loss: 0.023, a㏄:0.996, val_loss:0.090, val_acc:0.974\n",
            "epoch:84, loss: 0.022, a㏄:0.996, val_loss:0.089, val_acc:0.975\n",
            "epoch:85, loss: 0.022, a㏄:0.996, val_loss:0.091, val_acc:0.974\n",
            "epoch:86, loss: 0.021, a㏄:0.996, val_loss:0.090, val_acc:0.974\n",
            "epoch:87, loss: 0.021, a㏄:0.996, val_loss:0.090, val_acc:0.974\n",
            "epoch:88, loss: 0.020, a㏄:0.996, val_loss:0.089, val_acc:0.974\n",
            "epoch:89, loss: 0.019, a㏄:0.997, val_loss:0.091, val_acc:0.974\n",
            "epoch:90, loss: 0.019, a㏄:0.997, val_loss:0.092, val_acc:0.973\n",
            "epoch:91, loss: 0.018, a㏄:0.997, val_loss:0.090, val_acc:0.974\n",
            "epoch:92, loss: 0.017, a㏄:0.997, val_loss:0.090, val_acc:0.974\n",
            "epoch:93, loss: 0.017, a㏄:0.997, val_loss:0.090, val_acc:0.974\n",
            "epoch:94, loss: 0.016, a㏄:0.997, val_loss:0.091, val_acc:0.974\n",
            "epoch:95, loss: 0.016, a㏄:0.997, val_loss:0.090, val_acc:0.975\n",
            "epoch:96, loss: 0.015, a㏄:0.998, val_loss:0.090, val_acc:0.974\n",
            "epoch:97, loss: 0.015, a㏄:0.998, val_loss:0.091, val_acc:0.974\n",
            "epoch:98, loss: 0.015, a㏄:0.998, val_loss:0.090, val_acc:0.974\n",
            "epoch:99, loss: 0.014, a㏄:0.998, val_loss:0.092, val_acc:0.974\n",
            "epoch:100, loss: 0.014, a㏄:0.998, val_loss:0.091, val_acc:0.974\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-29ec3731f757>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: range() takes no keyword arguments"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch\n",
        "import torch.nn as nn \n",
        "import torch.optim as optimizers\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import random_split\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "'''\n",
        "  (1) modelの実装\n",
        "'''\n",
        "class DNN(nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "    super().__init__()\n",
        "    self.l1 = nn.Linear(input_dim, hidden_dim)\n",
        "    self.a1 = nn.ReLU()\n",
        "    self.d1 = nn.Dropout(0.5)\n",
        "\n",
        "    self.l2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "    self.a2 = nn.ReLU()\n",
        "    self.d2 = nn.Dropout(0.5)\n",
        "\n",
        "    self.l3 = nn.Linear(hidden_dim,hidden_dim)\n",
        "    self.a3 = nn.ReLU()\n",
        "    self.d3 = nn.Dropout(0.5)\n",
        "\n",
        "    self.l4 = nn.Linear(hidden_dim, output_dim)\n",
        "    \n",
        "    self.layers = [self.l1, self.a1,\n",
        "                    self.l2, self.a2,\n",
        "                    self.l3, self.a3,\n",
        "                    self.l4]\n",
        "\n",
        "  def forward(self,x):\n",
        "    for layer in self.layers:\n",
        "      x = layer(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  np.random.seed(123)\n",
        "  #torch用の乱数シード\n",
        "  torch.manual_seed(123)\n",
        "\n",
        "  #deviceに実行環境を格納して同じコードでCPUでもGPUでも対応できるように\n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "'''\n",
        "  1 データの準備\n",
        "'''\n",
        "root = os.path.join('~', '.torch', 'mnist')\n",
        "#numpyをTテンensorに変換し、さらにTensorの次元を(28，28)から(784、)に変換\n",
        "transform = transforms.Compose([transforms.ToTensor(), lambda x: x.view(-1)])\n",
        "\n",
        "mnist_train = datasets.MNIST(root = root,\n",
        "                             download = True,\n",
        "                             train = True,\n",
        "                             transform = transform)\n",
        "n_samples = len(mnist_train)\n",
        "n_train = int(n_samples * 0.8)\n",
        "n_val = n_samples - n_train\n",
        "#2番目の引数 = 分割するデータ数\n",
        "#8:2に分割して検証データを作る\n",
        "mnist_train, mnist_val = random_split(mnist_train, [n_train, n_val])\n",
        "\n",
        "\n",
        "mnist_test = datasets.MNIST(root = root,\n",
        "                            download = True,\n",
        "                            train = False,\n",
        "                            transform = transform)\n",
        "\n",
        "\n",
        "\n",
        "#学習に用いるためにデータセットをDataLoaderオブジェクトに変換\n",
        "#minibatch学習の時にバッチ単位でデータ処理できる、かつ、各epochでデータシャッフル可能\n",
        "train_dataloader = DataLoader(mnist_train, \n",
        "                              batch_size = 100,\n",
        "                              shuffle = True)\n",
        "\n",
        "test_dataloader = DataLoader(mnist_test,\n",
        "                             batch_size = 100,\n",
        "                             shuffle = False)\n",
        "val_dataloader = DataLoader(mnist_test,\n",
        "                            batch_size = 100,\n",
        "                            shuffle = False)\n",
        "\n",
        "'''\n",
        "  2 モデルの構築\n",
        "'''\n",
        "model = DNN(784, 200, 10).to(device)\n",
        "\n",
        "'''\n",
        "  3　モデルの学習\n",
        "'''\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optimizers.SGD(model.parameters(), lr = 0.01)\n",
        "\n",
        "def compute_loss(t, y):\n",
        "  return criterion(y, t)\n",
        "\n",
        "def train_step(x, t):\n",
        "  #dropoutは訓練時とテスト時で挙動が異なるので書き忘れない！\n",
        "  model.train()\n",
        "  preds = model(x)\n",
        "  loss = compute_loss(t, preds)\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  return loss, preds\n",
        "#勾配を計算する必要がないのでtest_stepと同じ処理\n",
        "def val_step(x, t):\n",
        "  model.eval()\n",
        "  preds = model(x)\n",
        "  loss = criterion(preds, t)\n",
        "  return loss, preds\n",
        "\n",
        "epochs = 100\n",
        "#誤差と正解率の推移を保持するためのもの\n",
        "hist = {'val_loss':[], 'val_accuracy':[]}\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  train_loss = 0.\n",
        "  train_acc = 0.\n",
        "  val_loss = 0.\n",
        "  val_acc = 0.\n",
        "\n",
        "  for(x, t) in train_dataloader:\n",
        "    x,t = x.to(device), t.to(device)\n",
        "    loss, preds = train_step(x,t)\n",
        "    train_loss += loss.item()\n",
        "    #accuracy_socreはテンソル型をうけとれないので.tolist()を実行\n",
        "    train_acc += accuracy_score(t.tolist(), preds.argmax(dim = -1).tolist())\n",
        "  \n",
        "  train_loss /= len(train_dataloader)\n",
        "  train_acc /= len(train_dataloader)\n",
        "\n",
        "  \n",
        "  for(x, t) in val_dataloader:\n",
        "    x,t = x.to(device), t.to(device)\n",
        "    loss, preds = val_step(x,t)\n",
        "    val_loss += loss.item()\n",
        "    #accuracy_socreはテンソル型をうけとれないので.tolist()を実行\n",
        "    val_acc += accuracy_score(t.tolist(), preds.argmax(dim = -1).tolist())\n",
        "  \n",
        "  val_loss /= len(val_dataloader)\n",
        "  val_acc /= len(val_dataloader)\n",
        "\n",
        "  hist['val_loss'].append(val_loss)\n",
        "  hist['val_accuracy'].append(val_acc)\n",
        "\n",
        "\n",
        "  print('epoch:{}, loss: {:.3f}, a㏄:{:.3f}'\n",
        "        ', val_loss:{:.3f}, val_acc:{:.3f}'.format(epoch +1,\n",
        "                                                    train_loss,\n",
        "                                                    train_acc,\n",
        "                                                   val_loss,\n",
        "                                                   val_acc))\n",
        "\n",
        "'''\n",
        "  4 モデルの評価\n",
        "'''\n",
        "#検証データの誤差の可視化\n",
        "val_loss = hist['val_loss']\n",
        "val_acc = hist['val_accuracy']\n",
        "fig = plt.figure()\n",
        "plt.plot(range(len(val_loss)), val_loss, linewidth = 1)\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "\n",
        "plt.plot(range(len(val_acc), val_acc, linewidth = 1))\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('acc')\n",
        "\n",
        "\n",
        "\n",
        "def test_step(x,t):\n",
        "  return val_step(x,t)\n",
        "\n",
        "test_loss = 0.\n",
        "test_acc = 0.\n",
        "\n",
        "test_loss = 0.\n",
        "test_acc = 0.\n",
        "\n",
        "for(x,t) in test_dataloader:\n",
        "  x, t = x.to(device), t.to(device)\n",
        "  loss, preds = test_step(x,t)\n",
        "  test_loss += loss.item()\n",
        "  test_acc += accuracy_score(t.tolist(), preds.argmax(dim = -1).tolist())\n",
        "test_loss /= len(test_dataloader)\n",
        "test_acc /= len(test_dataloader)\n",
        "\n",
        "\n",
        "print('epoch:{}, loss: {:.3f}, acc:{:.3f}'.format(epoch +1,\n",
        "                                                    test_loss,\n",
        "                                                    test_acc))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "AK9ID9QYSiR-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JdaHLJxdQxAv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}